{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_Sentiment_Analysis_review_0616.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9fc92a49fa484fc6a7d5e730e3a7299c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cdcff4d0be994b9a8e9dbdd9cf8444c6",
              "IPY_MODEL_ddf633679fa44517953bf239b36548ed",
              "IPY_MODEL_30814aaa9cb14d6f8261de9254634eff"
            ],
            "layout": "IPY_MODEL_9380796140714d8298a0be7f9a45aa42"
          }
        },
        "cdcff4d0be994b9a8e9dbdd9cf8444c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86471c117044e358829f97cb5a395c3",
            "placeholder": "​",
            "style": "IPY_MODEL_0025897b79004397b05a1413a201addb",
            "value": "Downloading: 100%"
          }
        },
        "ddf633679fa44517953bf239b36548ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfff29e7a9b64735b8ca8c70e2abba01",
            "max": 714314041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b69c52b571a42bb9a75cfe690042754",
            "value": 714314041
          }
        },
        "30814aaa9cb14d6f8261de9254634eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af2b704971ef416fbbf43a1dae87a7f5",
            "placeholder": "​",
            "style": "IPY_MODEL_1582b9f72d6c4a76a1c516adc2b36742",
            "value": " 681M/681M [00:31&lt;00:00, 27.8MB/s]"
          }
        },
        "9380796140714d8298a0be7f9a45aa42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d86471c117044e358829f97cb5a395c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0025897b79004397b05a1413a201addb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfff29e7a9b64735b8ca8c70e2abba01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b69c52b571a42bb9a75cfe690042754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "af2b704971ef416fbbf43a1dae87a7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1582b9f72d6c4a76a1c516adc2b36742": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request"
      ],
      "metadata": {
        "id": "OojFRrenBuOM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1CVJUTAVf4jdvf4NNA_EYrBVVPWVEc2C9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUI-fwxKCXQP",
        "outputId": "6caa2276-97e1-4473-8668-368f8d05a39e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CVJUTAVf4jdvf4NNA_EYrBVVPWVEc2C9\n",
            "To: /content/comment_data_all.csv\n",
            "100% 48.2M/48.2M [00:00<00:00, 60.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('comment_data_all.csv', index_col=0)\n",
        "df.drop(['month', 'page'], axis=1, inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FLz3ZNZfCXN6",
        "outputId": "7bf0f73c-97e4-4333-ddca-6af47cb529a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  comment  star\n",
              "0       휘뚜루마뚜루 입고 다니기 좋습니다 로얄라이프제품들은 다 성공하는 듯!따숩고 예쁘기까...     5\n",
              "1                     어깨 깡패됩니다 기장감이나 털 재질 전체적으로 전부 맘에 들어요     5\n",
              "2                        바지 짱 편합니다ㅎㅎ 색깔도 너무 마음에 들고 핏도 좋네요     5\n",
              "3       입기 편하고 후드 탈부착 돼서 여러 무드 연출하기도 쉽고 좋은데 가죽냄새랑 마감이 ...     4\n",
              "4                 유니폼 브릿지 발마칸 코트! 세일.기간중 저렴하게 겟겟! 최고 말모말모     5\n",
              "...                                                   ...   ...\n",
              "344135                      가방이 아주 포인트 그 자체라서 빤딱하고 너무 좋아요     5\n",
              "344136                        보들보둘하고 사이즈도 괜찮고 색도 이쁘게 잘나왔음     5\n",
              "344137                    생각보다 클 줄 알고 샀다가 조금 작았네요 그래도 좋아요     4\n",
              "344138  생각보다 색상이 밝고 사이즈는 조금 작게 나온거 같아요.길이는 좀 길지만 수선안하고...     5\n",
              "344139                 매번 갖고 싶었던 ㅈ품 이였는데 이번에 얻어ㅛ네요ㅎㅎ감사합ㄴ닽     5\n",
              "\n",
              "[344140 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b4a49028-c218-48ab-9efb-7d652b71614b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>star</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>휘뚜루마뚜루 입고 다니기 좋습니다 로얄라이프제품들은 다 성공하는 듯!따숩고 예쁘기까...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>어깨 깡패됩니다 기장감이나 털 재질 전체적으로 전부 맘에 들어요</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>바지 짱 편합니다ㅎㅎ 색깔도 너무 마음에 들고 핏도 좋네요</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>입기 편하고 후드 탈부착 돼서 여러 무드 연출하기도 쉽고 좋은데 가죽냄새랑 마감이 ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>유니폼 브릿지 발마칸 코트! 세일.기간중 저렴하게 겟겟! 최고 말모말모</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344135</th>\n",
              "      <td>가방이 아주 포인트 그 자체라서 빤딱하고 너무 좋아요</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344136</th>\n",
              "      <td>보들보둘하고 사이즈도 괜찮고 색도 이쁘게 잘나왔음</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344137</th>\n",
              "      <td>생각보다 클 줄 알고 샀다가 조금 작았네요 그래도 좋아요</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344138</th>\n",
              "      <td>생각보다 색상이 밝고 사이즈는 조금 작게 나온거 같아요.길이는 좀 길지만 수선안하고...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344139</th>\n",
              "      <td>매번 갖고 싶었던 ㅈ품 이였는데 이번에 얻어ㅛ네요ㅎㅎ감사합ㄴ닽</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>344140 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4a49028-c218-48ab-9efb-7d652b71614b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4a49028-c218-48ab-9efb-7d652b71614b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4a49028-c218-48ab-9efb-7d652b71614b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "five = df[df['star'] == 5]\n",
        "four = df[df['star'] == 4]\n",
        "three = df[df['star'] == 3]\n",
        "two = df[df['star'] == 2]\n",
        "one = df[df['star'] == 1]"
      ],
      "metadata": {
        "id": "HQ6iBvfTSXjz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(five))\n",
        "print(len(four))\n",
        "print(len(three))               \n",
        "print(len(two))                \n",
        "print(len(one))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGHbBBzuSaGY",
        "outputId": "22b4c612-ce86-43bd-aa2a-997a8b0414f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "298540\n",
            "39242\n",
            "5332\n",
            "563\n",
            "463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 긍정, 부정 분할 후 라벨링"
      ],
      "metadata": {
        "id": "VXopc4fARFqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos = df[df['star'] == 5] #298,540\n",
        "nag = df[df['star'] < 5] #45,600"
      ],
      "metadata": {
        "id": "c06DB_4LCXLf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos['label'] = 1\n",
        "nag['label'] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8QsD5oiCXJG",
        "outputId": "f020bb2a-b4b0-4762-cbc4-6cd5f3404110"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 수 통일 (랜덤으로 하고 싶으면 아래 .sample 코드사용)"
      ],
      "metadata": {
        "id": "9RKFVFxSRMIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos = pos.iloc[:45000] # 이 부분만 데이터에 맞게 조정하면 됩니다\n",
        "nag = nag.iloc[:45000]"
      ],
      "metadata": {
        "id": "EwN1tss5CXGn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Test 데이터셋 분리"
      ],
      "metadata": {
        "id": "JSKHw6lnQ9x7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_train = pos.sample(frac=0.8, random_state=3000)\n",
        "pos_test = pos.drop(pos_train.index)"
      ],
      "metadata": {
        "id": "1fd3G8ndG0i0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nag_train = nag.sample(frac=0.8, random_state=3000)\n",
        "nag_test = nag.drop(nag_train.index)"
      ],
      "metadata": {
        "id": "9v_dxdVNJ8lZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.concat([pos_train, nag_train]).reset_index().drop(['index','star'], axis=1) # 72,000\n",
        "test = pd.concat([pos_test, nag_test]).reset_index().drop(['index','star'], axis=1) # 18,000"
      ],
      "metadata": {
        "id": "tpDpyGkgLVsN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "IxZbWbGNz_i2",
        "outputId": "14f67922-3c32-4de7-ff12-142d322b3aaf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 comment  label\n",
              "0                         디자인도 맘에 들고 가격은 좀 있지만 넓고 만족스러워요      1\n",
              "1      덩치가 커서 맞는 옷이 잘 없는데도 제가 입어도 크네요! 편하게 입기 너무 좋아요....      1\n",
              "2          지금 당장 캠퍼스를 활보하고싶은 디자인입니다. 스프링이 약한거만 빼면 다좋습니다.      1\n",
              "3             잘 안알려진 맛집 찾아버렸다 냄새난다는데 초반엔 심하고 입다보면 안나요 이쁨      1\n",
              "4      생각했던 딥그레이 색상이 잘 나와서 마음에 듭니다. 생각보다는 기장이 길기는 한데 ...      1\n",
              "...                                                  ...    ...\n",
              "71995  가격이 저렴하고 편하게 스타일링 하기 정말 좋습니다. 하지만 먼지나  보폴같은게 많...      0\n",
              "71996                       뒷부분이 너무 이뻐요 소재가 두꺼워서 손이 잘안갈듯      0\n",
              "71997  제 신체 스펙에 적당한 사이즈의 오버핏이며 지금인 늦 겨울에 딱 입기 알맞은 두께감입니다      0\n",
              "71998  기본템으로 무난무난 예쁜데 머리가 좀 납작해보여서 아쉬워요 그래도 싸게 주고 사서 ...      0\n",
              "71999  허리가 작다는 평 많이 봤는데 진짜 바지통에 비해 허리가 작은거 맞아요.. 통짜허리...      0\n",
              "\n",
              "[72000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c30d838-0e55-476a-9b5b-d1d61cfba6df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>디자인도 맘에 들고 가격은 좀 있지만 넓고 만족스러워요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>덩치가 커서 맞는 옷이 잘 없는데도 제가 입어도 크네요! 편하게 입기 너무 좋아요....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>지금 당장 캠퍼스를 활보하고싶은 디자인입니다. 스프링이 약한거만 빼면 다좋습니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>잘 안알려진 맛집 찾아버렸다 냄새난다는데 초반엔 심하고 입다보면 안나요 이쁨</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>생각했던 딥그레이 색상이 잘 나와서 마음에 듭니다. 생각보다는 기장이 길기는 한데 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71995</th>\n",
              "      <td>가격이 저렴하고 편하게 스타일링 하기 정말 좋습니다. 하지만 먼지나  보폴같은게 많...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71996</th>\n",
              "      <td>뒷부분이 너무 이뻐요 소재가 두꺼워서 손이 잘안갈듯</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71997</th>\n",
              "      <td>제 신체 스펙에 적당한 사이즈의 오버핏이며 지금인 늦 겨울에 딱 입기 알맞은 두께감입니다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71998</th>\n",
              "      <td>기본템으로 무난무난 예쁜데 머리가 좀 납작해보여서 아쉬워요 그래도 싸게 주고 사서 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71999</th>\n",
              "      <td>허리가 작다는 평 많이 봤는데 진짜 바지통에 비해 허리가 작은거 맞아요.. 통짜허리...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c30d838-0e55-476a-9b5b-d1d61cfba6df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c30d838-0e55-476a-9b5b-d1d61cfba6df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c30d838-0e55-476a-9b5b-d1d61cfba6df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.nunique(), test.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P07cDTvsKzcW",
        "outputId": "9839af48-2c5b-4ca7-8721-7c39881b8ea0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(comment    72000\n",
              " label          2\n",
              " dtype: int64, comment    18000\n",
              " label          2\n",
              " dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['label'].value_counts().plot(kind = 'bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "R85LJ8vKCW6f",
        "outputId": "d8fc0ada-98c2-4640-d979-1ea700b6456b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb552f4f90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.groupby('label').size().reset_index(name = 'count'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzdsWPnOCW4K",
        "outputId": "3fc4cd4d-9190-4d30-8072-711f7d2e922a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label  count\n",
            "0      0  36000\n",
            "1      1  36000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hugging Face의 트랜스포머 모델을 설치\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc1spTamEyWy",
        "outputId": "0edddeaa-073b-4138-8981-275c03401ee1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.19.4-py3-none-any.whl (4.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2 MB 8.4 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.7.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.7.0 pyyaml-6.0 tokenizers-0.12.1 transformers-4.19.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "id": "7C5E6xl9EyUw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "KnD0tIM1EySW",
        "outputId": "22ebddbc-e087-4164-d3ac-6acc46ff6cbf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             comment  label\n",
              "0                     디자인도 맘에 들고 가격은 좀 있지만 넓고 만족스러워요      1\n",
              "1  덩치가 커서 맞는 옷이 잘 없는데도 제가 입어도 크네요! 편하게 입기 너무 좋아요....      1\n",
              "2      지금 당장 캠퍼스를 활보하고싶은 디자인입니다. 스프링이 약한거만 빼면 다좋습니다.      1\n",
              "3         잘 안알려진 맛집 찾아버렸다 냄새난다는데 초반엔 심하고 입다보면 안나요 이쁨      1\n",
              "4  생각했던 딥그레이 색상이 잘 나와서 마음에 듭니다. 생각보다는 기장이 길기는 한데 ...      1\n",
              "5  편하고 핏도 마음에 들어요 근데 수선을 않하면 못입을 정도로 크긴하네요 수선 추천드릴게요      1\n",
              "6                        막 걸쳐입을수 있는 맨투맨입니다 싸게사서 더좋네요      1\n",
              "7  드디어 캠핑을 가서 사용했습니다. 정말 이쁘더군요. 사람들이 왜 돈들여서 화로대를 ...      1\n",
              "8                     핏감좋고 착용감좋고 재질도 좋은거 같아요. 역시 좋슴다      1\n",
              "9                           따뜻하니 겨울에 입고다니기 정말 좋은거같아요      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8de43968-e9eb-44c1-9d88-0d95f3634e3e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>디자인도 맘에 들고 가격은 좀 있지만 넓고 만족스러워요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>덩치가 커서 맞는 옷이 잘 없는데도 제가 입어도 크네요! 편하게 입기 너무 좋아요....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>지금 당장 캠퍼스를 활보하고싶은 디자인입니다. 스프링이 약한거만 빼면 다좋습니다.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>잘 안알려진 맛집 찾아버렸다 냄새난다는데 초반엔 심하고 입다보면 안나요 이쁨</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>생각했던 딥그레이 색상이 잘 나와서 마음에 듭니다. 생각보다는 기장이 길기는 한데 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>편하고 핏도 마음에 들어요 근데 수선을 않하면 못입을 정도로 크긴하네요 수선 추천드릴게요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>막 걸쳐입을수 있는 맨투맨입니다 싸게사서 더좋네요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>드디어 캠핑을 가서 사용했습니다. 정말 이쁘더군요. 사람들이 왜 돈들여서 화로대를 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>핏감좋고 착용감좋고 재질도 좋은거 같아요. 역시 좋슴다</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>따뜻하니 겨울에 입고다니기 정말 좋은거같아요</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8de43968-e9eb-44c1-9d88-0d95f3634e3e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8de43968-e9eb-44c1-9d88-0d95f3634e3e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8de43968-e9eb-44c1-9d88-0d95f3634e3e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리 - 훈련셋"
      ],
      "metadata": {
        "id": "Ogo_Cz_YIS9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리뷰 문장 추출\n",
        "sentences = train['comment']\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUiWamo9EyP9",
        "outputId": "166aa0d6-38df-4ddb-a068-92ee126e6f4c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                       디자인도 맘에 들고 가격은 좀 있지만 넓고 만족스러워요\n",
              "1    덩치가 커서 맞는 옷이 잘 없는데도 제가 입어도 크네요! 편하게 입기 너무 좋아요....\n",
              "2        지금 당장 캠퍼스를 활보하고싶은 디자인입니다. 스프링이 약한거만 빼면 다좋습니다.\n",
              "3           잘 안알려진 맛집 찾아버렸다 냄새난다는데 초반엔 심하고 입다보면 안나요 이쁨\n",
              "4    생각했던 딥그레이 색상이 잘 나와서 마음에 듭니다. 생각보다는 기장이 길기는 한데 ...\n",
              "5    편하고 핏도 마음에 들어요 근데 수선을 않하면 못입을 정도로 크긴하네요 수선 추천드릴게요\n",
              "6                          막 걸쳐입을수 있는 맨투맨입니다 싸게사서 더좋네요\n",
              "7    드디어 캠핑을 가서 사용했습니다. 정말 이쁘더군요. 사람들이 왜 돈들여서 화로대를 ...\n",
              "8                       핏감좋고 착용감좋고 재질도 좋은거 같아요. 역시 좋슴다\n",
              "9                             따뜻하니 겨울에 입고다니기 정말 좋은거같아요\n",
              "Name: comment, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lmyn5yUwEyNi",
        "outputId": "8d0703d0-3a29-4916-af86-318cf8917176"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 디자인도 맘에 들고 가격은 좀 있지만 넓고 만족스러워요 [SEP]',\n",
              " '[CLS] 덩치가 커서 맞는 옷이 잘 없는데도 제가 입어도 크네요! 편하게 입기 너무 좋아요. 얇아서 이거 한장만 입긴 힘들거 같아요 [SEP]',\n",
              " '[CLS] 지금 당장 캠퍼스를 활보하고싶은 디자인입니다. 스프링이 약한거만 빼면 다좋습니다. [SEP]',\n",
              " '[CLS] 잘 안알려진 맛집 찾아버렸다 냄새난다는데 초반엔 심하고 입다보면 안나요 이쁨 [SEP]',\n",
              " '[CLS] 생각했던 딥그레이 색상이 잘 나와서 마음에 듭니다. 생각보다는 기장이 길기는 한데 접어 입어도 좋고 조금 수선해도 예쁠 것 같아요! [SEP]',\n",
              " '[CLS] 편하고 핏도 마음에 들어요 근데 수선을 않하면 못입을 정도로 크긴하네요 수선 추천드릴게요 [SEP]',\n",
              " '[CLS] 막 걸쳐입을수 있는 맨투맨입니다 싸게사서 더좋네요 [SEP]',\n",
              " '[CLS] 드디어 캠핑을 가서 사용했습니다. 정말 이쁘더군요. 사람들이 왜 돈들여서 화로대를 좋은거 사나했더랍니다. 이제 다시 돌아가긴 틀린것같아요 불멍 다운 불멍을  해보니, 최고에요!! [SEP]',\n",
              " '[CLS] 핏감좋고 착용감좋고 재질도 좋은거 같아요. 역시 좋슴다 [SEP]',\n",
              " '[CLS] 따뜻하니 겨울에 입고다니기 정말 좋은거같아요 [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 추출\n",
        "labels = train['label'].values\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IomyhmQEyLI",
        "outputId": "1a996420-262f-48b3-8a74-0b539721680d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dHnMhUrEyIo",
        "outputId": "a768a63c-8f63-4c2e-84d3-a14e12c65e0e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 디자인도 맘에 들고 가격은 좀 있지만 넓고 만족스러워요 [SEP]\n",
            "['[CLS]', '디', '##자인', '##도', '맘', '##에', '들', '##고', '가', '##격', '##은', '좀', '있지만', '넓', '##고', '만', '##족', '##스', '##러', '##워', '##요', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL1wxTuCEyGV",
        "outputId": "f10a39f3-a2c7-433b-923c-cbbeb733b870"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  9122, 86150, 12092,  9253, 10530,  9117, 11664,  8843,\n",
              "       45465, 10892,  9682, 76123,  9007, 11664,  9248, 52560, 12605,\n",
              "       30873, 69592, 48549,   102,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArXLbsATEyD8",
        "outputId": "d3101fae-a404-450d-c35a-7ee284829fad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels, \n",
        "                                                                                    random_state=2018, \n",
        "                                                                                    test_size=0.1)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=2018, \n",
        "                                                       test_size=0.1)\n",
        "\n",
        "# 데이터를 파이토치의 텐서로 변환\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebn-VB4uEyBc",
        "outputId": "b7e1cd71-1b34-48c8-f5ec-427bf130b5e4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   101,   9186,  86732,  15001,   9952,  33797,   8932,  13890, 105197,\n",
            "         12092,   9131,   9256,  11664,   9012,  14646,  37712,  12092,   9847,\n",
            "         66554,  14523,  48549,    102,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "tensor([   101,   9904, 118666,  57362,   8934,  70221,   9954,  28911,   8933,\n",
            "         28911,  11261,   9270, 119192,  11664,   9583,  92564, 118855,  10530,\n",
            "         80244,   9645,  12965,  16323,  14867,   8939,  12692,  12453,   9270,\n",
            "        119192,  12965,  48549,    102,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "ISb9bs48Ex_C"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리 - 테스트셋"
      ],
      "metadata": {
        "id": "AQW1wiL5INU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 리뷰 문장 추출\n",
        "sentences = test['comment']\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nci7qdQ_Ex8u",
        "outputId": "9cb569b0-dfa4-4f97-e792-4263aa27a1ad"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                     바지 짱 편합니다ㅎㅎ 색깔도 너무 마음에 들고 핏도 좋네요\n",
              "1                크롭이라 너무 짧긴하지만 팔길이도 적당하고 기모라 따뜻해서 좋아요.\n",
              "2    핏이 넘모 이뻐요 좀 얇아서 히트텍이랑 입어야 됩니당 편하고 해서 받고 사일동안 오...\n",
              "3                      데이지 자수가 이뻐요 옷입을때 포인트 주기 좋을거 같아요\n",
              "4                             무신사스텐다드 반팔티 레이어드하기 딱좋습니다\n",
              "5                        너무  좋습니다  엑스트라오디너리  믿고 사는 브랜드\n",
              "6                  딸아이 교복에 입으려고 구입했어요 색상도 좋고 스포티해서 좋아요\n",
              "7                     사이즈 큼직하고 오버합니다 디자인 이쁘고 색상도 딱좋아요!\n",
              "8     친한동생이 입고있어서 이뻐서 따라샀는데 역시 너무 이쁘네요 시보리도 짱짱하고 따뜻합니다\n",
              "9         싸게 사서 일이나 운동할 때 살 신고 있습니다 뭐..많이 신었어요 사진은 ㅎㅎ;\n",
              "Name: comment, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT의 입력 형식에 맞게 변환\n",
        "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "sentences[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnCoxl3MEx6X",
        "outputId": "e47f54de-1af8-49d0-8b68-f7d1363538ed"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[CLS] 바지 짱 편합니다ㅎㅎ 색깔도 너무 마음에 들고 핏도 좋네요 [SEP]',\n",
              " '[CLS] 크롭이라 너무 짧긴하지만 팔길이도 적당하고 기모라 따뜻해서 좋아요. [SEP]',\n",
              " '[CLS] 핏이 넘모 이뻐요 좀 얇아서 히트텍이랑 입어야 됩니당 편하고 해서 받고 사일동안 오지게 입었네용 [SEP]',\n",
              " '[CLS] 데이지 자수가 이뻐요 옷입을때 포인트 주기 좋을거 같아요 [SEP]',\n",
              " '[CLS] 무신사스텐다드 반팔티 레이어드하기 딱좋습니다 [SEP]',\n",
              " '[CLS] 너무  좋습니다  엑스트라오디너리  믿고 사는 브랜드 [SEP]',\n",
              " '[CLS] 딸아이 교복에 입으려고 구입했어요 색상도 좋고 스포티해서 좋아요 [SEP]',\n",
              " '[CLS] 사이즈 큼직하고 오버합니다 디자인 이쁘고 색상도 딱좋아요! [SEP]',\n",
              " '[CLS] 친한동생이 입고있어서 이뻐서 따라샀는데 역시 너무 이쁘네요 시보리도 짱짱하고 따뜻합니다 [SEP]',\n",
              " '[CLS] 싸게 사서 일이나 운동할 때 살 신고 있습니다 뭐..많이 신었어요 사진은 ㅎㅎ; [SEP]']"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨 추출\n",
        "labels = test['label'].values\n",
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrtAT61IGHsF",
        "outputId": "e27bae70-4286-4e5d-aa6c-3788c55b85b0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ave5uWRWGHpw",
        "outputId": "8b878060-c64b-4464-b357-79445171a854"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] 바지 짱 편합니다ㅎㅎ 색깔도 너무 마음에 들고 핏도 좋네요 [SEP]\n",
            "['[CLS]', '바', '##지', '짱', '[UNK]', '색', '##깔', '##도', '너', '##무', '마', '##음', '##에', '들', '##고', '[UNK]', '좋', '##네', '##요', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 토큰의 최대 시퀀스 길이\n",
        "MAX_LEN = 128\n",
        "\n",
        "# 토큰을 숫자 인덱스로 변환\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "\n",
        "# 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRtMCsQXGhAv",
        "outputId": "79e5332b-fa04-48e7-c24f-73c431df0847"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   101,   9318,  12508,   9718,    100,   9416, 118674,  12092,\n",
              "         9004,  32537,   9246,  32158,  10530,   9117,  11664,    100,\n",
              "         9685,  77884,  48549,    102,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 어텐션 마스크 초기화\n",
        "attention_masks = []\n",
        "\n",
        "# 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "# 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoLXxwWZGHnI",
        "outputId": "a3a06cce-b93c-4b19-a256-ee64df307585"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\n",
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnbawpH-HC36",
        "outputId": "0fdab496-9ff1-439d-f0d0-ca3e7af17d1f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   101,   9318,  12508,   9718,    100,   9416, 118674,  12092,   9004,\n",
            "         32537,   9246,  32158,  10530,   9117,  11664,    100,   9685,  77884,\n",
            "         48549,    102,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 배치 사이즈\n",
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "QH3Zbcv_HEW0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 생성"
      ],
      "metadata": {
        "id": "TDW6NTB6IKDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 디바이스 이름 구함\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# GPU 디바이스 이름 검사\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyFeXNhDGOYu",
        "outputId": "e0034a1f-a43e-465f-d8c2-b400b0f0b695"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 디바이스 설정\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFg_Uo2SGOWv",
        "outputId": "ea998abb-f1d9-4a08-8341-9642021e96ea"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 분류를 위한 BERT 모델 생성\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9fc92a49fa484fc6a7d5e730e3a7299c",
            "cdcff4d0be994b9a8e9dbdd9cf8444c6",
            "ddf633679fa44517953bf239b36548ed",
            "30814aaa9cb14d6f8261de9254634eff",
            "9380796140714d8298a0be7f9a45aa42",
            "d86471c117044e358829f97cb5a395c3",
            "0025897b79004397b05a1413a201addb",
            "bfff29e7a9b64735b8ca8c70e2abba01",
            "0b69c52b571a42bb9a75cfe690042754",
            "af2b704971ef416fbbf43a1dae87a7f5",
            "1582b9f72d6c4a76a1c516adc2b36742"
          ]
        },
        "id": "7dCTk0Y0GOUH",
        "outputId": "59fa3a90-f523-4df0-8749-f308fe90c66f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9fc92a49fa484fc6a7d5e730e3a7299c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 10\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 처음에 학습률을 조금씩 변화시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd0rXExZGOSC",
        "outputId": "e2cd8afa-0e1d-4f47-b7a0-80416f1c3919"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "Z-R_bX_eIHIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "ig1DegD_GOPh"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "r9YyGLfEGONL"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 출력 로짓 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-qr_rWpGOKu",
        "outputId": "5e0dd4e9-3740-4eb4-875d-2d46855df56f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.52\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.67\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.66\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.34\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.33\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.63\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.64\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.65\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.61\n",
            "  Validation took: 0:00:07\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch   500  of    507.    Elapsed: 0:03:10.\n",
            "\n",
            "  Average training loss: 0.10\n",
            "  Training epcoh took: 0:03:12\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.62\n",
            "  Validation took: 0:00:06\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 테스트셋 평가"
      ],
      "metadata": {
        "id": "gCPin4waHNAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 출력 로짓 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    \n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TEgLrGOHMDX",
        "outputId": "f291a84c-3b4f-49d5-a9e9-70c367a6497b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Batch   100  of    563.    Elapsed: 0:00:12.\n",
            "  Batch   200  of    563.    Elapsed: 0:00:23.\n",
            "  Batch   300  of    563.    Elapsed: 0:00:35.\n",
            "  Batch   400  of    563.    Elapsed: 0:00:46.\n",
            "  Batch   500  of    563.    Elapsed: 0:00:58.\n",
            "\n",
            "Accuracy: 0.96\n",
            "Test took: 0:01:05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새로운 문장 테스트"
      ],
      "metadata": {
        "id": "DzqTiedAHSo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 데이터 변환\n",
        "def convert_input_data(sentences):\n",
        "\n",
        "    # BERT의 토크나이저로 문장을 토큰으로 분리\n",
        "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "    # 입력 토큰의 최대 시퀀스 길이\n",
        "    MAX_LEN = 128\n",
        "\n",
        "    # 토큰을 숫자 인덱스로 변환\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "    \n",
        "    # 문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    # 어텐션 마스크 초기화\n",
        "    attention_masks = []\n",
        "\n",
        "    # 어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n",
        "    # 패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        attention_masks.append(seq_mask)\n",
        "\n",
        "    # 데이터를 파이토치의 텐서로 변환\n",
        "    inputs = torch.tensor(input_ids)\n",
        "    masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return inputs, masks"
      ],
      "metadata": {
        "id": "SXkmD4P9Ex4M"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 테스트\n",
        "def test_sentences(sentences):\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 문장을 입력 데이터로 변환\n",
        "    inputs, masks = convert_input_data(sentences)\n",
        "\n",
        "    # 데이터를 GPU에 넣음\n",
        "    b_input_ids = inputs.to(device)\n",
        "    b_input_mask = masks.to(device)\n",
        "            \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 출력 로짓 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "mv7tGMaGHcQx"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit = test_sentences(['이쁩니다 절개디테일이 있어서 안심심하네요 추천합니다']) # 기존 5점\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "metadata": {
        "id": "QVb_bBy2YB6E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cb2f790-6a5e-4f86-8ea5-8013acdf174c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.5179805 -0.998993 ]\n",
            " [ 3.9820218 -3.3740156]\n",
            " [-3.156609   2.2718387]\n",
            " [-3.5837388  2.4538698]\n",
            " [ 3.65174   -3.3027687]\n",
            " [-2.7845368  1.8626267]\n",
            " [-2.7894688  2.1935997]\n",
            " [ 2.4272916 -2.4925742]\n",
            " [-3.9010863  3.5390859]\n",
            " [ 3.3730915 -3.3452513]\n",
            " [ 3.8397384 -3.4357095]\n",
            " [-3.9163632  3.5295644]\n",
            " [-2.9541621  2.7230744]\n",
            " [ 3.4861386 -3.0363452]\n",
            " [-3.5888426  3.071887 ]\n",
            " [-4.1192575  3.623753 ]]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit = test_sentences(['이런 옷 처음 사보는데 어떻게 매치해서 입어야할지 고민... 그냥 딱 노랑노랑한 무슨 농구복같은 느낌 ㅎㅎㅎ']) # 기존 3점\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wUwPBs1Hzl4",
        "outputId": "fa1beb72-9696-4e7b-cfb4-439bf113e12a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.5179805 -0.998993 ]\n",
            " [ 3.9820218 -3.3740156]\n",
            " [-3.156609   2.2718387]\n",
            " [-3.5837388  2.4538698]\n",
            " [ 3.65174   -3.3027687]\n",
            " [-2.7845368  1.8626267]\n",
            " [-2.7894688  2.1935997]\n",
            " [ 2.4272916 -2.4925742]\n",
            " [-3.9010863  3.5390859]\n",
            " [ 3.3730915 -3.3452513]\n",
            " [ 3.8397384 -3.4357095]\n",
            " [-3.9163632  3.5295644]\n",
            " [-2.9541621  2.7230744]\n",
            " [ 3.4861386 -3.0363452]\n",
            " [-3.5888426  3.071887 ]\n",
            " [-4.1192575  3.623753 ]]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logit = test_sentences(['별 하나도 아까움 사진으로 확인하세요 절대비추 앞판천은 괜찮은데 뒷판은 쪼글쪼글 뒷판을 안볼거라 생각한건지..']) # 기존 1점\n",
        "\n",
        "print(logits)\n",
        "print(np.argmax(logits))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mRdP1KzHzj9",
        "outputId": "31026510-2bca-4954-fff8-65c7c37eab71"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.5179805 -0.998993 ]\n",
            " [ 3.9820218 -3.3740156]\n",
            " [-3.156609   2.2718387]\n",
            " [-3.5837388  2.4538698]\n",
            " [ 3.65174   -3.3027687]\n",
            " [-2.7845368  1.8626267]\n",
            " [-2.7894688  2.1935997]\n",
            " [ 2.4272916 -2.4925742]\n",
            " [-3.9010863  3.5390859]\n",
            " [ 3.3730915 -3.3452513]\n",
            " [ 3.8397384 -3.4357095]\n",
            " [-3.9163632  3.5295644]\n",
            " [-2.9541621  2.7230744]\n",
            " [ 3.4861386 -3.0363452]\n",
            " [-3.5888426  3.071887 ]\n",
            " [-4.1192575  3.623753 ]]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kWbZm3zOIck1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}